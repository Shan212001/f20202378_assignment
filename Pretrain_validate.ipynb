{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.64285714 0.67857143 0.66071429 0.57142857 0.60714286]\n",
      "Mean Cross-Validation Accuracy: 0.6321428571428572\n",
      "Detailed Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                     Africa       1.00      1.00      1.00        19\n",
      "                       Asia       1.00      1.00      1.00         8\n",
      "                     Europe       1.00      1.00      1.00        10\n",
      "              North America       1.00      0.88      0.93        16\n",
      "              South America       1.00      1.00      1.00        18\n",
      "                 Automotive       1.00      1.00      1.00        20\n",
      "                     Energy       1.00      1.00      1.00        10\n",
      "                  Logistics       0.93      1.00      0.96        13\n",
      "                 Technology       1.00      0.94      0.97        18\n",
      "             Transportation       1.00      1.00      1.00        10\n",
      "       Competition/Features       0.00      0.00      0.00         0\n",
      "         Expansion/Features       0.00      0.00      0.00         0\n",
      "         Features/Expansion       0.88      0.94      0.91        16\n",
      "        Features/Innovation       0.82      0.56      0.67        16\n",
      "          Features/Positive       1.00      1.00      1.00         1\n",
      "        Features/Technology       0.73      0.44      0.55        18\n",
      "          Positive/Features       0.00      0.00      0.00         0\n",
      "Pricing Discussion/Features       1.00      0.77      0.87        13\n",
      "          Security/Features       1.00      1.00      1.00         7\n",
      "\n",
      "                  micro avg       0.96      0.89      0.92       213\n",
      "                  macro avg       0.81      0.76      0.78       213\n",
      "               weighted avg       0.95      0.89      0.91       213\n",
      "                samples avg       0.96      0.89      0.92       213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHASHANK GAUTAM\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\SHASHANK GAUTAM\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support, \n",
    "    multilabel_confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import random\n",
    "import joblib  # For saving the model\n",
    "\n",
    "# Updated Data Augmenter Class\n",
    "class DataAugmenter:\n",
    "    @staticmethod\n",
    "    def synonym_replacement(text, n=1):\n",
    "        \"\"\"Replace n random words with modified version\"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) < n:\n",
    "            return text\n",
    "        \n",
    "        for _ in range(n):\n",
    "            idx = random.randint(0, len(words) - 1)\n",
    "            words[idx] = words[idx].upper()  # Simple modification\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    @staticmethod\n",
    "    def back_translation(text):\n",
    "        \"\"\"Simulate back translation by slightly modifying the text\"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) < 3:\n",
    "            return text\n",
    "        \n",
    "        mid = len(words) // 2\n",
    "        words[mid-1:mid+2] = words[mid+1:mid-1:-1]\n",
    "        return ' '.join(words)\n",
    "\n",
    "# Updated Classifier for EV Charging Data\n",
    "class EVChargingClassifier:\n",
    "    def __init__(self):\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.augmenter = DataAugmenter()\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        words = text.split()\n",
    "        cleaned_words = [self.lemmatizer.lemmatize(word) for word in words if word not in self.stop_words]\n",
    "        return ' '.join(cleaned_words)\n",
    "    \n",
    "    def augment_data(self, X, y):\n",
    "        \"\"\"\n",
    "        Perform data augmentation with class distribution analysis\n",
    "        \"\"\"\n",
    "        # Analyze class distribution before augmentation\n",
    "        class_distribution_before = np.sum(y, axis=0)\n",
    "        \n",
    "        augmented_X = list(X)\n",
    "        augmented_y = list(y)\n",
    "        \n",
    "        # Identify minority classes\n",
    "        minority_indices = np.where(class_distribution_before < np.median(class_distribution_before))[0]\n",
    "        \n",
    "        # Augmentation for minority classes\n",
    "        for idx in minority_indices:\n",
    "            # Find instances of this minority class\n",
    "            minority_sample_indices = np.where(y[:, idx] == 1)[0]\n",
    "            \n",
    "            for sample_idx in minority_sample_indices:\n",
    "                # Apply augmentation techniques\n",
    "                aug_text = random.choice([self.augmenter.synonym_replacement(X[sample_idx]), \n",
    "                                          self.augmenter.back_translation(X[sample_idx])])\n",
    "                \n",
    "                augmented_X.append(aug_text)\n",
    "                augmented_y.append(y[sample_idx])\n",
    "        \n",
    "        # Convert back to numpy arrays\n",
    "        X_augmented = np.array(augmented_X)\n",
    "        y_augmented = np.array(augmented_y)\n",
    "        \n",
    "        # Analyze class distribution after augmentation\n",
    "        class_distribution_after = np.sum(y_augmented, axis=0)\n",
    "        \n",
    "        # Visualization of class distribution\n",
    "        self.plot_class_distribution(\n",
    "            class_distribution_before, \n",
    "            class_distribution_after, \n",
    "            minority_indices\n",
    "        )\n",
    "        \n",
    "        return X_augmented, y_augmented\n",
    "    \n",
    "    def plot_class_distribution(self, before, after, minority_indices):\n",
    "        \"\"\"\n",
    "        Visualize class distribution before and after augmentation\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Create bar plot\n",
    "        plt.bar(\n",
    "            range(len(before)), \n",
    "            before, \n",
    "            alpha=0.5, \n",
    "            label='Before Augmentation',\n",
    "            color='blue'\n",
    "        )\n",
    "        plt.bar(\n",
    "            range(len(after)), \n",
    "            after, \n",
    "            alpha=0.5, \n",
    "            label='After Augmentation',\n",
    "            color='red'\n",
    "        )\n",
    "        \n",
    "        # Highlight minority classes\n",
    "        for idx in minority_indices:\n",
    "            plt.text(\n",
    "                idx, \n",
    "                after[idx], \n",
    "                f'â†‘{after[idx] - before[idx]}', \n",
    "                horizontalalignment='center',\n",
    "                color='green'\n",
    "            )\n",
    "        \n",
    "        plt.title('Class Distribution Before and After Augmentation')\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Number of Instances')\n",
    "        plt.xticks(range(len(before)), range(1, len(before) + 1), rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('class_distribution_augmentation.png')\n",
    "        plt.close()\n",
    "\n",
    "# Model Evaluation Class\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, X_test, y_test, class_names):\n",
    "        \"\"\"\n",
    "        Initialize the ModelEvaluator.\n",
    "\n",
    "        Parameters:\n",
    "        - model: The trained model pipeline.\n",
    "        - X_test: The test features.\n",
    "        - y_test: The test labels (multi-label).\n",
    "        - class_names: A list of names corresponding to each class.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detailed_evaluation(self):\n",
    "        \"\"\"Comprehensive model evaluation\"\"\"\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        # Number of classes\n",
    "        num_classes = self.y_test.shape[1]\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"Detailed Classification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred, target_names=self.class_names))\n",
    "\n",
    "        # Confusion matrices\n",
    "        cm = multilabel_confusion_matrix(self.y_test, y_pred)\n",
    "\n",
    "        # Dynamically determine grid dimensions for subplots\n",
    "        rows = (num_classes + 2) // 3  # Number of rows (3 columns max)\n",
    "        plt.figure(figsize=(15, rows * 5))\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            plt.subplot(rows, 3, i + 1)  # Adjust grid size dynamically\n",
    "            sns.heatmap(cm[i], annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(self.class_names[i])  # Use class names for subplot titles\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrices_with_class_names.png')\n",
    "        plt.close()\n",
    "# Main Workflow\n",
    "def main():\n",
    "    # Load dataset\n",
    "    df = pd.read_csv('input.csv')\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = EVChargingClassifier()\n",
    "    \n",
    "    # Preprocess text\n",
    "    df['Preprocessed_Description'] = df['Description'].apply(classifier.preprocess_text)\n",
    "    \n",
    "    # Prepare labels (one-hot encoded)\n",
    "    mlb_region = MultiLabelBinarizer()\n",
    "    mlb_sector = MultiLabelBinarizer()\n",
    "    mlb_feature = MultiLabelBinarizer()\n",
    "    \n",
    "    region_labels = mlb_region.fit_transform(df['Region'].apply(lambda x: [x]))\n",
    "    sector_labels = mlb_sector.fit_transform(df['Sector'].apply(lambda x: [x]))\n",
    "    feature_labels = mlb_feature.fit_transform(df['Feature_Type'].apply(lambda x: [x]))\n",
    "    \n",
    "    # Combine labels\n",
    "    y = np.column_stack((region_labels, sector_labels, feature_labels))\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = (\n",
    "        list(mlb_region.classes_) + \n",
    "        list(mlb_sector.classes_) + \n",
    "        list(mlb_feature.classes_)\n",
    "    )\n",
    "    \n",
    "    # Augment data\n",
    "    X_augmented, y_augmented = classifier.augment_data(\n",
    "        df['Preprocessed_Description'].values, y\n",
    "    )\n",
    "    \n",
    "    # Split augmented data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_augmented, y_augmented, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create and train pipeline\n",
    "    pipeline = Pipeline([ \n",
    "        ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "        ('clf', MultiOutputClassifier(SVC(kernel='linear', random_state=42)))\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cross_val_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
    "    print(f\"Mean Cross-Validation Accuracy: {cross_val_scores.mean()}\")\n",
    "    \n",
    "    # Fit model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the model and encoders\n",
    "    joblib.dump(pipeline, 'ev_charging_classifier_model.pkl')  # Save the model\n",
    "    joblib.dump(mlb_region, 'mlb_region_encoder.pkl')  # Save region encoder\n",
    "    joblib.dump(mlb_sector, 'mlb_sector_encoder.pkl')  # Save sector encoder\n",
    "    joblib.dump(mlb_feature, 'mlb_feature_encoder.pkl')  # Save feature encoder\n",
    "    \n",
    "    print(\"Model and encoders saved successfully.\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluator = ModelEvaluator(pipeline, X_test, y_test, class_names)  # Pass class_names\n",
    "    evaluator.detailed_evaluation()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
